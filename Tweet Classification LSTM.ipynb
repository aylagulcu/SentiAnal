{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28676,
     "status": "ok",
     "timestamp": 1525800155883,
     "user": {
      "displayName": "Emrah Tema",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102019531740135725055"
     },
     "user_tz": -180
    },
    "id": "7dH0F1Q2HDGX",
    "outputId": "701a3bd0-384b-4839-a670-aba673019522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-HR-LfYnHV4e"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "#4/AAB7t09pV-WSRzHDG9WFfneYyEWpjiULxtVhTc7s5GH1p216RGD7Dgw\n",
    "#4/AAA9HQIkK7T5WM10fPa9bzri0trmCXaVmXD8NlLqs8ZWLG93Up4ZXzw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qKr8tClmBvvF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ncf_h-t0B2Km"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('drive/Colab Notebooks/data.txt')\n",
    "data.columns = ['cumle','sinif']\n",
    "data = data[['cumle','sinif']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0reKvMGDH9R2"
   },
   "outputs": [],
   "source": [
    "# Veri setimizin işlenebilmesi için text verileri numaralara çevirmemiz gerekir.\n",
    "# Keras bu işlem için hazır bir mekanizma sunmaktadır.\n",
    "# Tokenizer sınıfı data içerisinde verilen cümleleri analiz ederek. Kelimelerin sıklıklarını hesaplar.\n",
    "# Parameter: num_words = En sık geçen 25000 kelimeye odaklan. Diğerleri önemli değil\n",
    "tokenizer = Tokenizer(split=' ',num_words=25000)\n",
    "# Her bir kelimenin sıklığını(frekansını) hesaplar.\n",
    "tokenizer.fit_on_texts(data['cumle'].values)\n",
    "# Tüm cümleler tam sayı dizisine dönüştürülür.\n",
    "X = tokenizer.texts_to_sequences(data['cumle'].values)\n",
    "# Bütün metinlerimiz 400 sütundan oluşan bir dizi ile temsil edilecek.\n",
    "# Çok kısa metinler 0'lar ile doldurulacak. Çok uzun metinler ise kesilecek.\n",
    "X = pad_sequences(X,maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 937,
     "status": "ok",
     "timestamp": 1525800288690,
     "user": {
      "displayName": "Emrah Tema",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102019531740135725055"
     },
     "user_tz": -180
    },
    "id": "xSPPtGNVIDd9",
    "outputId": "6ded9075-b036-4d34-e3f0-2751953ca39b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 128\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    # Her bir kelimenin temsil edileceği vektör boyutu. Bu örnek için her bir kelime 128 boyutunda\n",
    "    # bir vektör ile temsil edilir.\n",
    "    model.add(Embedding(25000, embed_dim,input_length = X.shape[1], dropout=0.2))\n",
    "    model.add(LSTM(lstm_out, dropout_U=0.2, dropout_W=0.2))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "  # Çıktılarımızı kategorik hale getirdik. (Opsiyonel)\n",
    "Y = pd.get_dummies(data['sinif']).values\n",
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517821,
     "status": "ok",
     "timestamp": 1525804440484,
     "user": {
      "displayName": "Emrah Tema",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102019531740135725055"
     },
     "user_tz": -180
    },
    "id": "0y9tU9U_IUqN",
    "outputId": "c9e06f88-406d-43e7-e7e9-7d4f83745474"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 104s - loss: 1.1521 - acc: 0.5460\n",
      "Epoch 2/5\n",
      " - 103s - loss: 0.3329 - acc: 0.9104\n",
      "Epoch 3/5\n",
      " - 102s - loss: 0.1021 - acc: 0.9732\n",
      "Epoch 4/5\n",
      " - 102s - loss: 0.0458 - acc: 0.9906\n",
      "Epoch 5/5\n",
      " - 102s - loss: 0.0281 - acc: 0.9927\n",
      "score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Verinin %90'i train, %10'si test verisi olacak şekilde ayrılır.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.1, random_state = 1)\n",
    "\n",
    "model = build_model()\n",
    "# Oluşturulan model train verileri ile eğitilir. Yapay Sinir Ağı eğitilmeye başlar.\n",
    "# nb_epoch: İterasyon sayısı\n",
    "model.fit(X_train, Y_train, nb_epoch = 5, batch_size=32, verbose = 2)\n",
    "# Train verileri ile model eğitildikten sonra test dataları ile doğruluk oranlarına bakılır.\n",
    "score = model.evaluate(X_test, Y_test, verbose = 2)\n",
    "print(\"score: %.2f\" % (score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1525773095097,
     "user": {
      "displayName": "Emrah Tema",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102019531740135725055"
     },
     "user_tz": -180
    },
    "id": "40uzHZ9xIhEm",
    "outputId": "7f23a0f6-cd3c-462b-a6c7-92489b9fbb1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.4506195e-03 5.3389353e-04 1.8809482e-02 9.7420597e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 0: Kızmak, 1: Korkmak, 2: Mutluluk, 3:Üzüntü\n",
    "\n",
    "my_text = [\"harca kardeş üzül şu erken doğ çok erken\"]\n",
    "\n",
    "# Verilen örnekler Tokenizer yapısı ile tam sayı dizisine dönüştürülür\n",
    "# Daha sonra eğitilen modele sırayla verilerek anlam analizi sonuçları elde edilir.\n",
    "# Her Cümlenin yüzde kaç olumlu ve olumsuz olduğuna dair bilgiler çıktı olarak verilir.\n",
    "sequences = tokenizer.texts_to_sequences(my_text)\n",
    "data = pad_sequences(sequences, maxlen=400)\n",
    "predictions = model.predict(data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BJFzJnVqJ95e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "LSTM_Test.ipynb adlı dosyanın kopyası",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
